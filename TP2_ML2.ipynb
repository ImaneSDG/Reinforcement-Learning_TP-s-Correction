{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "723d3558-09fe-48a2-b3c0-12521f46eb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de60b535-1117-4e0d-b68c-573be9376897",
   "metadata": {},
   "source": [
    "## Ex1 : Exploration de l'Environnement FrozenLake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44479a0b-9531-4128-928f-65e9eef211d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, {'prob': 1})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(\"FrozenLake-v1\", is_slippery=True )\n",
    "env.reset() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "799265e9-525d-4ffe-9e61-57ea32c086bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Espace d'états : Discrete(16)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Espace d'états : {env.observation_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddf928b1-1b4c-4696-80ca-6c7dd4f718b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Espace d'actions : Discrete(4)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Espace d'actions : {env.action_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "268348de-b031-4141-9878-9bf9768d4e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action : 1, Observation : 1, Reward : 0.0\n",
      "Action : 1, Observation : 2, Reward : 0.0\n",
      "Action : 2, Observation : 6, Reward : 0.0\n",
      "Action : 0, Observation : 10, Reward : 0.0\n",
      "Action : 2, Observation : 6, Reward : 0.0\n",
      "Action : 0, Observation : 5, Reward : 0.0\n",
      "Action : 2, Observation : 1, Reward : 0.0\n",
      "Action : 1, Observation : 2, Reward : 0.0\n",
      "Action : 2, Observation : 6, Reward : 0.0\n",
      "Action : 1, Observation : 10, Reward : 0.0\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    action = env.action_space.sample() \n",
    "    observation, reward, done, _, _ = env.step(action) \n",
    "    print(f\"Action : {action}, Observation : {observation}, Reward : {reward}\")\n",
    "    if done:\n",
    "        env.reset()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ffd91f-b242-4d16-9e25-13e198a59e58",
   "metadata": {},
   "source": [
    "## Ex2 : Implémentation et Initialisation de la Q-Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ffd0916-9339-4dca-9e59-807d1dc0a2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q-Table initialisée :\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "num_states = env.observation_space.n\n",
    "num_actions = env.action_space.n\n",
    "q_table = np.zeros((num_states, num_actions))\n",
    "\n",
    "print(\"\\nQ-Table initialisée :\")\n",
    "print(q_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c6a2a5-59bb-4e7f-b6cf-5b19a61f6907",
   "metadata": {},
   "source": [
    "## Ex3 : Implémentation du Q-Learning avec Mise à Jour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8064c38-d8b3-4796-8e99-71e98fb82fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q-Table après apprentissage : \n",
      "\n",
      "[[0.49739674 0.48944025 0.4898178  0.48469667]\n",
      " [0.32559709 0.34802785 0.30290304 0.46017407]\n",
      " [0.39900433 0.26374148 0.28310021 0.29910152]\n",
      " [0.09008194 0.11455173 0.04618486 0.09253383]\n",
      " [0.51081404 0.3310545  0.40905429 0.38222129]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.35070756 0.13143948 0.16299476 0.0791155 ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.42151183 0.39962833 0.32766961 0.54333262]\n",
      " [0.36934971 0.56699971 0.33657123 0.32554302]\n",
      " [0.53639672 0.3213424  0.4653868  0.23329603]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.50958051 0.48809908 0.635766   0.33697742]\n",
      " [0.73088285 0.77721387 0.7450151  0.73556533]\n",
      " [0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Paramètres\n",
    "alpha = 0.1   \n",
    "gamma = 0.99     \n",
    "epsilon = 1.0    # Exploration initiale\n",
    "epsilon_decay = 0.995  \n",
    "num_episodes = 5000  \n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()[0]\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        # Choix de l'action (exploration vs exploitation)\n",
    "        if np.random.rand() < epsilon:\n",
    "            action = env.action_space.sample()  # Exploration\n",
    "        else:\n",
    "            action = np.argmax(q_table[state, :])  # Exploitation\n",
    "        \n",
    "        new_state, reward, done, _, _ = env.step(action)\n",
    "\n",
    "        # MAJ de la Q-Table \n",
    "        q_table[state, action] = q_table[state, action] + alpha * (reward + gamma * np.max(q_table[new_state, :]) - q_table[state, action])\n",
    "        \n",
    "        state = new_state  # MAJ d'état\n",
    "\n",
    "    # Réduction de epsilon pour moins d'exploration au fil du temps\n",
    "    epsilon = max(0.01, epsilon * epsilon_decay)\n",
    "\n",
    "print(\"\\nQ-Table après apprentissage : \\n\")\n",
    "print(q_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06adef9a-c7d1-41c5-afae-5c3a8d1f78a7",
   "metadata": {},
   "source": [
    "## Ex4 : Évaluation des Performances de l'Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4d5d1e2c-f390-4f37-93c2-a4bf6ecaae36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taux de réussite : 81/100 (81.00%)\n"
     ]
    }
   ],
   "source": [
    "num_test_episodes = 100\n",
    "successes = 0\n",
    "\n",
    "for _ in range(num_test_episodes):\n",
    "    state = env.reset()[0]\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action = np.argmax(q_table[state, :])  \n",
    "        new_state, reward, done, _, _ = env.step(action)\n",
    "        state = new_state\n",
    "\n",
    "    if reward > 0:  \n",
    "        successes += 1\n",
    "\n",
    "print(f\"Taux de réussite : {successes}/{num_test_episodes} ({successes/num_test_episodes*100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fc39e6-5c79-4eae-86c7-e9b3c38a5a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19777f5-6752-4337-b330-60ccb114bfbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abd5c00-8bed-48d3-aefc-f13a9508b6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
